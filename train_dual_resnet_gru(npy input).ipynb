{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train dual resnet gru\n",
    "pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from ysp_func import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from einops import rearrange\n",
    "from torchsummary import summary\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision import transforms\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = \"C:/Users/\" + os.getenv('USERNAME') +\"/Desktop/DCASE2024-Task10-Dataset/simulation\"\n",
    "gen_name = 'gen_sound_v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_path, dir_name):\n",
    "        super(CustomDataset, self).__init__()\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.dir_name = dir_name\n",
    "        self.df_datainfo = pd.read_csv(f'{self.root_path}/{self.dir_name}.csv')        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df_datainfo.loc[index]['path']\n",
    "        feat1_name = filename.replace(self.dir_name, f'{self.dir_name}_feat1_npy').replace('.flac', '.npy')\n",
    "        feat1_path = f'{self.root_path}/{feat1_name}'\n",
    "        feat2_name = filename.replace(self.dir_name, f'{self.dir_name}_feat2_npy').replace('.flac', '.npy')\n",
    "        feat2_path = f'{self.root_path}/{feat2_name}'\n",
    "        \n",
    "        feat1 = np.load(feat1_path)\n",
    "        feat2 = np.load(feat2_path)\n",
    "        \n",
    "        self.x1_data = torch.FloatTensor(feat1)\n",
    "        self.x2_data = torch.FloatTensor(feat2)\n",
    "        \n",
    "        label = self.df_datainfo.loc[index][['car_left', 'car_right', 'cv_left', 'cv_right']]        \n",
    "        y = torch.FloatTensor(label)\n",
    "        self.y_data = y\n",
    "\n",
    "        return self.x1_data, self.x2_data, self.y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_datainfo)\n",
    "    \n",
    "    def get_filename(self, index):        \n",
    "        return self.df_datainfo.loc[index]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "size : torch.Size([128, 1874, 4]) / torch.Size([128, 1874, 6]) / torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(path0, gen_name)\n",
    "dataset_size = dataset.__len__()\n",
    "print(dataset_size)\n",
    "\n",
    "train_size = int(dataset_size * 0.8)\n",
    "valid_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "temp = train_dataset.__getitem__(0)\n",
    "print(f'size : {temp[0].size()} / {temp[1].size()} / {temp[2].size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 0\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "''' dual_ResNet_GRU Model class (Lightning) '''\n",
    "class dual_ResNet_GRU(L.LightningModule):\n",
    "    def __init__(self, hidden_dimension, output_dimension, dropout):\n",
    "        super().__init__()\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []                \n",
    "\n",
    "        resnet_temp = resnet18()        # pretrained=True\n",
    "        resnet_temp.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False) # in : 4ch, out : 64ch\n",
    "        resnet_temp.avgpool = nn.AdaptiveAvgPool2d((59, 1))\n",
    "        resnet_temp = nn.Sequential(*list(resnet_temp.children())[:-1])\n",
    "        self.resnet_spectrogram = resnet_temp\n",
    "\n",
    "        resnet_temp = resnet18()        # pretrained=True\n",
    "        resnet_temp.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False) # in : 6ch, out : 64ch\n",
    "        resnet_temp.avgpool = nn.AdaptiveAvgPool2d((59, 1))\n",
    "        resnet_temp = nn.Sequential(*list(resnet_temp.children())[:-1])\n",
    "        self.resnet_sthd = resnet_temp\n",
    "        \n",
    "        input_dimension = 1024\n",
    "        self.gru_layer = nn.GRU(input_dimension, \n",
    "                           hidden_dimension, \n",
    "                           num_layers=2, \n",
    "                           bidirectional=False,     # bidirectional=True, # Not Bi-GRU\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc_layer = nn.Linear(hidden_dimension, output_dimension)\n",
    " \n",
    "    def forward(self, x1, x2):\n",
    "        '''input: (batch_size, feat_bins, time_steps, channels)'''        \n",
    "        x1 = rearrange(x1, \"batch feat time ch -> batch ch time feat\")\n",
    "        x1 = self.resnet_spectrogram(x1)        \n",
    "        x2 = rearrange(x2, \"batch feat time ch -> batch ch time feat\")\n",
    "        x2 = self.resnet_sthd(x2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = rearrange(x, \"batch ch time feat -> batch time (ch feat)\")\n",
    "\n",
    "        x, hidden = self.gru_layer(x)        \n",
    "        \n",
    "        x = self.fc_layer(hidden[-1])  # hidden state # x[:, -1, :] # Take the output of the last time step\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_num):\n",
    "        train_x1, train_x2, train_y = batch\n",
    "        y_pred = self(train_x1, train_x2)        \n",
    "        training_loss = loss_func(y_pred, train_y)\n",
    "        \n",
    "        self.log('train_loss', training_loss, on_epoch=True, prog_bar=True)\n",
    "        return training_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_num):\n",
    "        val_x1, val_x2, val_y = batch\n",
    "        y_pred = self(val_x1, val_x2)        \n",
    "        val_loss = loss_func(y_pred, val_y)\n",
    "        self.validation_step_outputs.append(val_loss)\n",
    "        \n",
    "        self.log('val_loss', val_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return val_loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.validation_step_outputs.clear()        \n",
    "        return avg_loss\n",
    "\n",
    "    def test_step(self, batch, batch_num):        \n",
    "        test_x1, test_x2, test_y = batch\n",
    "        y_pred = self(test_x1, test_x2)        \n",
    "        test_loss = loss_func(y_pred, test_y)\n",
    "        self.test_step_outputs.append(test_loss)\n",
    "        \n",
    "        self.log('test_loss', test_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return test_loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.test_step_outputs).mean()\n",
    "        self.test_step_outputs.clear()\n",
    "        return avg_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)     # 1e-3\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 4개 : 'car_left', 'car_right', 'cv_left', 'cv_right' # 각각 회귀\n",
    "model = dual_ResNet_GRU(hidden_dimension=256, output_dimension=4, dropout=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model.to('cuda'), [(128, 1874, 4), (128, 1874, 6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # 모니터링할 메트릭\n",
    "    patience=10,            # 성능 향상이 없을 때 기다리는 에포크 수\n",
    "    verbose=True,           # 로그 출력 여부\n",
    "    mode='min'              # 'min' (최소화) 또는 'max' (최대화)\n",
    ")\n",
    "\n",
    "''' GRU model train '''\n",
    "trainer = L.Trainer(max_epochs=100, accelerator=\"gpu\", default_root_dir = 'logs_gen1', callbacks=[early_stopping])  # EarlyStopping 콜백 추가\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' GRU model test '''\n",
    "trainer.test()  # trainer.test('ckpt_path='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size : torch.Size([128, 1874, 4]) / torch.Size([128, 1874, 6]) / torch.Size([4])\n",
      "tensor([4., 6., 1., 2.])\n",
      "tensor([3.4177, 5.5061, 1.6080, 1.8384], grad_fn=<SqueezeBackward0>)\n",
      "tensor([3., 6., 2., 2.], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_data = test_dataset.__getitem__(7)\n",
    "test_x1, test_x2, test_y = test_data\n",
    "print(f'size : {test_x1.size()} / {test_x2.size()} / {test_y.size()}')\n",
    "print(test_y)\n",
    "\n",
    "y_pred = model(test_x1.unsqueeze(0), test_x2.unsqueeze(0))\n",
    "print(y_pred.squeeze())\n",
    "print(y_pred.squeeze().round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가\n",
    "다른 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = \"C:/Users/\" + os.getenv('USERNAME') +\"/Desktop/DCASE2024-Task10-Dataset/simulation\"\n",
    "gen_name = 'gen_sound_v0'       # 600개 # 평가할 데이터 (학습안된 데이터)\n",
    "test_dataset = CustomDataset(path0, gen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dual_ResNet_GRU(\n",
       "  (resnet_spectrogram): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(59, 1))\n",
       "  )\n",
       "  (resnet_sthd): Sequential(\n",
       "    (0): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(59, 1))\n",
       "  )\n",
       "  (gru_layer): GRU(1024, 256, num_layers=2, batch_first=True, dropout=0.05)\n",
       "  (fc_layer): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "default_root_dir = 'logs_gen1'\n",
    "ver_num = \"0\"\n",
    "ckpt_path = f\"{default_root_dir}/lightning_logs/version_{ver_num}/checkpoints\"\n",
    "ckpt_name = [file for file in os.listdir(ckpt_path) if file.endswith('.ckpt')][0]  # ckpt_name = \"epoch=99-step=12000.ckpt\"\n",
    "\n",
    "model = dual_ResNet_GRU.load_from_checkpoint(f\"{ckpt_path}/{ckpt_name}\", hidden_dimension=256, output_dimension=4, dropout=0.05)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1fbf2a06a24a7590c80a41a9159cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터 확인\n",
    "test_csv_filename = f'{gen_name}_test.csv'\n",
    "\n",
    "columns = ['car_left', 'car_right', 'cv_left', 'cv_right', 'path']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# mse = []\n",
    "for idx in tqdm(range(test_dataset.__len__())):\n",
    "    test_data = test_dataset.__getitem__(idx)\n",
    "    test_x1, test_x2, test_y = test_data\n",
    "    \n",
    "    y_pred = model(test_x1.unsqueeze(0).to(device), test_x2.unsqueeze(0).to(device))\n",
    "    y_pred = y_pred.squeeze().round().to('cpu')\n",
    "    \n",
    "    data_filename = test_dataset.get_filename(idx)\n",
    "    \n",
    "    df.loc[idx] = y_pred.tolist() + [data_filename]\n",
    "        \n",
    "    # mse 계산?\n",
    "    # mse.append(((test_y - y_pred) ** 2).mean().tolist)\n",
    "\n",
    "df[['car_left', 'car_right', 'cv_left', 'cv_right']] = df[['car_left', 'car_right', 'cv_left', 'cv_right']].astype(int)\n",
    "df.to_csv(test_csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
