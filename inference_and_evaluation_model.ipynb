{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    " Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm.auto import tqdm\n",
    "from preprocessing_sig2feat import *\n",
    "from ysp_func import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from einops import rearrange\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_path, dir_name):\n",
    "        super(CustomDataset, self).__init__()\n",
    "\n",
    "        # fs = 16000\n",
    "        self.fframe = 2**10      # 1024\n",
    "        self.delay = int(self.fframe/4)    # 256\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.dir_name = dir_name\n",
    "        self.df_datainfo = pd.read_csv(f'{self.root_path}/{self.dir_name}.csv')        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df_datainfo.loc[index]['path']\n",
    "        file_path = f'{self.root_path}/{filename}'        \n",
    "                \n",
    "        sig, fs = librosa.load(file_path, sr=None, mono=False)\n",
    "        sig = sig / np.max(np.abs(sig))\n",
    "        \n",
    "        feat1 = feature_spectrogram_tensor(sig, fs, self.fframe, device)\n",
    "        self.x1_data = standardization_tensor(feat1)\n",
    "\n",
    "        feat2 = feature_sthd_tensor(sig, fs, self.fframe, self.delay, device)\n",
    "        self.x2_data = standardization_tensor(feat2)\n",
    "        \n",
    "        label = self.df_datainfo.loc[index][['car_left', 'car_right', 'cv_left', 'cv_right']]\n",
    "        y = torch.FloatTensor(label)\n",
    "        self.y_data = y\n",
    "\n",
    "        return self.x1_data, self.x2_data, self.y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_datainfo)\n",
    "    \n",
    "    def get_filename(self, index):        \n",
    "        return self.df_datainfo.loc[index]['path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 0\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "''' dual_ResNet_GRU Model class (Lightning) '''\n",
    "class dual_ResNet_GRU(L.LightningModule):\n",
    "    def __init__(self, hidden_dimension, output_dimension, dropout):\n",
    "        super().__init__()\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []                \n",
    "\n",
    "        resnet_temp = resnet18()        # pretrained=True\n",
    "        resnet_temp.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False) # in : 4ch, out : 64ch\n",
    "        resnet_temp.avgpool = nn.AdaptiveAvgPool2d((59, 1))\n",
    "        resnet_temp = nn.Sequential(*list(resnet_temp.children())[:-1])\n",
    "        self.resnet_spectrogram = resnet_temp\n",
    "\n",
    "        resnet_temp = resnet18()        # pretrained=True\n",
    "        resnet_temp.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False) # in : 6ch, out : 64ch\n",
    "        resnet_temp.avgpool = nn.AdaptiveAvgPool2d((59, 1))\n",
    "        resnet_temp = nn.Sequential(*list(resnet_temp.children())[:-1])\n",
    "        self.resnet_sthd = resnet_temp\n",
    "        \n",
    "        input_dimension = 1024\n",
    "        self.gru_layer = nn.GRU(input_dimension, \n",
    "                           hidden_dimension, \n",
    "                           num_layers=2, \n",
    "                           bidirectional=False,     # bidirectional=True, # Not Bi-GRU\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc_layer = nn.Linear(hidden_dimension, output_dimension)\n",
    " \n",
    "    def forward(self, x1, x2):\n",
    "        '''input: (batch_size, feat_bins, time_steps, channels)'''        \n",
    "        x1 = rearrange(x1, \"batch feat time ch -> batch ch time feat\")\n",
    "        x1 = self.resnet_spectrogram(x1)        \n",
    "        x2 = rearrange(x2, \"batch feat time ch -> batch ch time feat\")\n",
    "        x2 = self.resnet_sthd(x2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = rearrange(x, \"batch ch time feat -> batch time (ch feat)\")\n",
    "\n",
    "        x, hidden = self.gru_layer(x)        \n",
    "        \n",
    "        x = self.fc_layer(hidden[-1])  # hidden state # x[:, -1, :] # Take the output of the last time step\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_num):\n",
    "        train_x1, train_x2, train_y = batch\n",
    "        y_pred = self(train_x1, train_x2)        \n",
    "        training_loss = loss_func(y_pred, train_y)\n",
    "        \n",
    "        self.log('train_loss', training_loss, on_epoch=True, prog_bar=True)\n",
    "        return training_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_num):\n",
    "        val_x1, val_x2, val_y = batch\n",
    "        y_pred = self(val_x1, val_x2)        \n",
    "        val_loss = loss_func(y_pred, val_y)\n",
    "        self.validation_step_outputs.append(val_loss)\n",
    "        \n",
    "        self.log('val_loss', val_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return val_loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.validation_step_outputs.clear()        \n",
    "        return avg_loss\n",
    "\n",
    "    def test_step(self, batch, batch_num):        \n",
    "        test_x1, test_x2, test_y = batch\n",
    "        y_pred = self(test_x1, test_x2)        \n",
    "        test_loss = loss_func(y_pred, test_y)\n",
    "        self.test_step_outputs.append(test_loss)\n",
    "        \n",
    "        self.log('test_loss', test_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return test_loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.test_step_outputs).mean()\n",
    "        self.test_step_outputs.clear()\n",
    "        return avg_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)     # 1e-3\n",
    "\n",
    "    # def train_dataloader(self):\n",
    "    #     return DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    # def val_dataloader(self):\n",
    "    #     return DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    # def test_dataloader(self):\n",
    "    #     return DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가\n",
    "다른 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가할 데이터\n",
    "loc_dict = {1: 'loc1', 2: 'loc2', 3: 'loc3', 4: 'loc4', 5: 'loc5', 6: 'loc6'}\n",
    "loc_nn = 1\n",
    "# path0 = \"C:/Users/\" + os.getenv('USERNAME') + f\"/Desktop/DCASE2024-Task10-Dataset/{loc_dict[loc_nn]}\"\n",
    "# test_name = 'val'\n",
    "path0 = \"C:/Users/\" + os.getenv('USERNAME') + f\"/Desktop/DCASE2024-Task10-Evaluation_Dataset/{loc_dict[loc_nn]}\"\n",
    "test_name = 'test'      \n",
    "test_dataset = CustomDataset(path0, test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "logs_name = f'logs_gen3_{loc_dict[loc_nn]}'\n",
    "ver_num = 3\n",
    "ckpt_path = f\"{logs_name}/lightning_logs/version_{ver_num}/checkpoints\"\n",
    "ckpt_name = [file for file in os.listdir(ckpt_path) if file.endswith('.ckpt')][0]\n",
    "\n",
    "model = dual_ResNet_GRU.load_from_checkpoint(f\"{ckpt_path}/{ckpt_name}\", hidden_dimension=256, output_dimension=4, dropout=0.05)\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 확인\n",
    "test_csv_filename = f'{path0}/{test_name}_{logs_name}_{ver_num}.csv'\n",
    "\n",
    "columns = ['path', 'car_left', 'car_right', 'cv_left', 'cv_right']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for idx in tqdm(range(test_dataset.__len__())):\n",
    "    test_data = test_dataset.__getitem__(idx)\n",
    "    test_x1, test_x2, test_y = test_data\n",
    "    \n",
    "    y_pred = model(test_x1.unsqueeze(0).to(device), test_x2.unsqueeze(0).to(device))\n",
    "    y_pred = y_pred.squeeze().to('cpu')         # y_pred = y_pred.squeeze().round().to('cpu')\n",
    "    \n",
    "    data_filename = test_dataset.get_filename(idx)\n",
    "    \n",
    "    y_pred[y_pred < 0] = 0\n",
    "    df.loc[idx] = [data_filename] + y_pred.tolist()\n",
    "\n",
    "df[['car_left', 'car_right', 'cv_left', 'cv_right']] = df[['car_left', 'car_right', 'cv_left', 'cv_right']]     #.astype(int)\n",
    "df.to_csv(test_csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- ktau_corr\n",
    "- rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_csv_name = f'{path0}/{test_name}.csv'\n",
    "pred_csv_name = f'{path0}/{test_name}_{logs_name}_{ver_num}.csv'\n",
    "\n",
    "TARGET_CLASSES = [\"car_left\", \"car_right\", \"cv_left\", \"cv_right\"]\n",
    "METRICS = [\"Kendall's Tau Corr\", \"RMSE\"]\n",
    "\n",
    "output_path = f'{pred_csv_name}_metrics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_left</th>\n",
       "      <th>car_right</th>\n",
       "      <th>cv_left</th>\n",
       "      <th>cv_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kendall's Tau Corr</th>\n",
       "      <td>0.773</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.875</td>\n",
       "      <td>2.013</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    car_left  car_right  cv_left  cv_right\n",
       "Kendall's Tau Corr     0.773      0.664    0.716     0.645\n",
       "RMSE                   1.875      2.013    0.580     0.528"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load predictions and ground truth\n",
    "df_gt = pd.read_csv(gt_csv_name)\n",
    "df_pred = pd.read_csv(pred_csv_name)\n",
    "\n",
    "if len(df_pred) != len(df_gt):\n",
    "    raise ValueError(\"Predictions and ground truth must contain the same number of samples.\")\n",
    "\n",
    "len_df = len(df_pred)\n",
    "df_gt.sort_values(\"path\", inplace=True)\n",
    "df_pred.sort_values(\"path\", inplace=True)\n",
    "\n",
    "ktau_corr_dict, rmse_dict = {}, {}\n",
    "for label in TARGET_CLASSES:\n",
    "    gt_scores = df_gt[label].values\n",
    "    pred_scores = df_pred[label].values\n",
    "\n",
    "    # RMSE score\n",
    "    rmse = np.sqrt(1.0 / len(gt_scores) * np.sum((gt_scores - pred_scores) ** 2.0))\n",
    "\n",
    "    # correlation-based metrics\n",
    "    ktau_corr = kendalltau(gt_scores, pred_scores).correlation\n",
    "\n",
    "    # output results\n",
    "    ktau_corr_dict[label] = round(ktau_corr, 3)\n",
    "    rmse_dict[label] = round(rmse, 3)\n",
    "\n",
    "results = pd.DataFrame([ktau_corr_dict, rmse_dict], index=METRICS)\n",
    "results.fillna(0, inplace=True)\n",
    "results.to_csv(output_path, index=True, index_label=\"Metric\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "loc_dict = {1: 'loc1', 2: 'loc2', 3: 'loc3', 4: 'loc4', 5: 'loc5', 6: 'loc6'}\n",
    "loc_nn = 6\n",
    "path0 = \"C:/Users/\" + os.getenv('USERNAME') + f\"/Desktop/DCASE2024-Task10-Evaluation_Dataset/{loc_dict[loc_nn]}\"\n",
    "test_name = 'test'\n",
    "\n",
    "csv_name = f'{path0}/{test_name}.csv'\n",
    "f = open(csv_name, \"w\", newline='')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['path', 'car_left', 'car_right', 'cv_left', 'cv_right']) ## 여기 주목!\n",
    "\n",
    "list_filepath = list_all_file_path(f'{path0}/{test_name}')\n",
    "for filepath in list_filepath:\n",
    "    filepath = filepath.replace('\\\\','/')\n",
    "    filename = filepath.split(f'{loc_dict[loc_nn]}/')[-1]\n",
    "    \n",
    "    if '.flac' in filename:\n",
    "        # print(filename)\n",
    "        writer.writerow([filename])\n",
    "\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
